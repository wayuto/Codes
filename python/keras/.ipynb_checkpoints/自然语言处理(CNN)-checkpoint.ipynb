{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7d54e4de-27ef-4b38-b14a-b6b054074ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "595865aa-9b3e-49c4-9e1e-c634e9fc9f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'达音科   17 周年   倒 是 数据 最 好看 ， 而且 便宜'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "data = pd.read_csv('datasets/earphones.csv')\n",
    "\n",
    "#cut data\n",
    "cw = lambda x: list(jieba.cut(x))\n",
    "data['content'] = data['content'].apply(cw)\n",
    "\n",
    "#from list to string...\n",
    "max_doc_leg = max(len(x) for x in data['content'])\n",
    "print(max_doc_leg)\n",
    "texts = [' '.join(x) for x in data['content']]\n",
    "texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8095ec58-d898-4c22-9d2d-d457b6bd8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=30000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences = pad_sequences(sequences, maxlen=1700, padding='post')\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4d7524-84cd-476e-b837-0d100b8e4333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_text = tokenizer.word_index\n",
    "dict_text['所以']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4655806-6e56-4273-82c7-10f96c94cbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 129, 6083,   29, ...,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "477530fd-8a4a-4c6d-a993-0816d464e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "poslen, neglen = 0, 0\n",
    "leg = data['sentiment_value']\n",
    "for i in range(len(data['sentiment_value'])):\n",
    "    if leg[i] == 1:\n",
    "        poslen += 1\n",
    "    else:\n",
    "        neglen += 1\n",
    "\n",
    "positive_label = [[0, 1] for _ in range(poslen)]\n",
    "negative_label = [[1, 0] for _ in range(neglen)]\n",
    "y = np.concatenate([positive_label, negative_label], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2b2c36-adaa-4b43-b8f8-d273bbf77698",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(int(time()))\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "\n",
    "x_shuffled = sequences[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "test_sample_index = -1 * int(0.1 * float(len(y)))\n",
    "x_train, x_test = x_shuffled[:test_sample_index], x_shuffled[test_sample_index:]\n",
    "y_train, y_test = y_shuffled[:test_sample_index], y_shuffled[test_sample_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fe68bbbd-a275-4b4f-848d-7a99b1f505c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(1700, ))\n",
    "embedding_layer = Embedding(30000, 128, input_length=1700)\n",
    "embedding_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "cnn1 = Conv1D(filters=32, kernel_size=3, activation='relu')(embedding_sequences)\n",
    "cnn1 = MaxPooling1D(pool_size=5)(cnn1)\n",
    "cnn1 = Conv1D(filters=32, kernel_size=3, activation='relu')(cnn1)\n",
    "cnn1 = MaxPooling1D(pool_size=5)(cnn1)\n",
    "cnn1 = Conv1D(filters=32, kernel_size=3, activation='relu')(cnn1)\n",
    "cnn1 = MaxPooling1D(pool_size=37)(cnn1)\n",
    "cnn1 = Flatten()(cnn1)\n",
    "\n",
    "cnn2 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding_sequences)\n",
    "cnn2 = MaxPooling1D(pool_size=5)(cnn2)\n",
    "cnn2 = Conv1D(filters=32, kernel_size=4, activation='relu')(cnn2)\n",
    "cnn2 = MaxPooling1D(pool_size=5)(cnn2)\n",
    "cnn2 = Conv1D(filters=32, kernel_size=4, activation='relu')(cnn2)\n",
    "cnn2 = MaxPooling1D(pool_size=36)(cnn2)\n",
    "cnn2 = Flatten()(cnn2)\n",
    "\n",
    "cnn3 = Conv1D(filters=32, kernel_size=5, activation='relu')(embedding_sequences)\n",
    "cnn3 = MaxPooling1D(pool_size=5)(cnn3)\n",
    "cnn3 = Conv1D(filters=32, kernel_size=5, activation='relu')(cnn3)\n",
    "cnn3 = MaxPooling1D(pool_size=5)(cnn3)\n",
    "cnn3 = Conv1D(filters=32, kernel_size=5, activation='relu')(cnn3)\n",
    "cnn3 = MaxPooling1D(pool_size=35)(cnn3)\n",
    "cnn3 = Flatten()(cnn3)\n",
    "\n",
    "merge = concatenate([cnn1, cnn2, cnn3], axis=1)\n",
    "x = Dense(128, activation='relu')(merge)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(2, activation='softmax')(x)\n",
    "model = Model(sequence_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "878c5f1f-dda2-49e9-99ce-1a5445ab5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model/nlp_cnn.h5')\n",
    "# model.compile(\n",
    "#     optimizer=Adam(),\n",
    "#     loss=categorical_crossentropy, \n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "# model.fit(x_train, y_train, batch_size=256, epochs=25, validation_data=(x_test, y_test))\n",
    "# model.save('model/nlp_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d1191289-e567-452e-bd2f-ad9dc407c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_think(content):\n",
    "    cw = list(jieba.cut(content))\n",
    "    word_id = []\n",
    "    for word in cw:\n",
    "        try:\n",
    "            temp = dict_text[word]\n",
    "            word_id.append(temp)\n",
    "        except:\n",
    "            word_id.append(0)\n",
    "    word_id = np.array(word_id)\n",
    "    word_id = word_id[np.newaxis, :]\n",
    "    sequences = pad_sequences(word_id, maxlen=1700, padding='post')\n",
    "    result = np.argmax(model.predict(sequences))\n",
    "    # result = model.predict(sequences)\n",
    "    if result == 1:\n",
    "        print(f\"Thank you~({result})\")\n",
    "    elif result == 0:\n",
    "        print(f\"Fuck you!({result})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4a8b0b3f-0e7d-494f-aef8-ceee424d071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "欢迎下次购买~(5.5004918976919726e-05)\n"
     ]
    }
   ],
   "source": [
    "from os import system\n",
    "\n",
    "system('clear')\n",
    "system('fortune | cowsay -f dragon-and-cow')\n",
    "while True:\n",
    "    I_think(input('Comment: '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
