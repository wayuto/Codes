{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212a94a2-8b0d-4397-8060-3b7d64947f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1292d38-0805-406a-b65e-dc7f502eef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'所以 趁着 还 没 爆 ， 赶紧 出手 。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "data = pd.read_csv('datasets/earphones_300.csv')\n",
    "\n",
    "#cut data\n",
    "cw = lambda x: list(jieba.cut(x))\n",
    "data['content'] = data['content'].apply(cw)\n",
    "\n",
    "#from list to string...\n",
    "max_doc_leg = max(len(x) for x in data['content'])\n",
    "print(max_doc_leg)\n",
    "texts = [' '.join(x) for x in data['content']]\n",
    "texts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d7dbd65-cd02-470e-95cd-d9faed628a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=30000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences = pad_sequences(sequences, maxlen=1700)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7545f0ad-e527-4e91-bdf7-ad1597a3e7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_text = tokenizer.word_index\n",
    "dict_text['所以']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289d44e2-c40c-4faa-8898-7b41acd680dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0, ..., 1360, 2445,    3], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915db7fc-a047-487f-9a9d-8738a8196ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "poslen, neglen = 0, 0\n",
    "leg = data['sentiment_value']\n",
    "for i in range(len(data['sentiment_value'])):\n",
    "    if leg[i] == 1:\n",
    "        poslen += 1\n",
    "    else:\n",
    "        neglen += 1\n",
    "\n",
    "positive_label = [[0, 1] for _ in range(poslen)]\n",
    "negative_label = [[1, 0] for _ in range(neglen)]\n",
    "y = np.concatenate([positive_label, negative_label], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8938ed44-095d-4834-b782-114fe476af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(int(time()))\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "\n",
    "x_shuffled = sequences[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "test_sample_index = -1 * int(0.1 * float(len(y)))\n",
    "x_train, x_test = x_shuffled[:test_sample_index], x_shuffled[test_sample_index:]\n",
    "y_train, y_test = y_shuffled[:test_sample_index], y_shuffled[test_sample_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accc5f98-5731-459a-b7fc-333ce447cdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(1700, ))\n",
    "embedding_layer = Embedding(30000, 128, input_length=1700)\n",
    "embedding_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "lstm = LSTM(10, dropout=0.2, recurrent_dropout=0.2)(embedding_sequences)\n",
    "lstm = Dense(16, activation='relu')(lstm)\n",
    "lstm = Dropout(0.5)(lstm)\n",
    "\n",
    "pred = Dense(2, activation='softmax')(lstm)\n",
    "model = Model(sequence_input, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a064168-70a7-413d-b587-eb45913e726f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(),\n\u001b[1;32m      3\u001b[0m     loss\u001b[38;5;241m=\u001b[39mcategorical_crossentropy, \n\u001b[1;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=categorical_crossentropy, \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "595bdf1f-db36-4cf4-9039-1bb9ab548b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_think(content):\n",
    "    cw = list(jieba.cut(content))\n",
    "    word_id = []\n",
    "    for word in cw:\n",
    "        try:\n",
    "            temp = dict_text[word]\n",
    "            word_id.append(temp)\n",
    "        except:\n",
    "            word_id.append(0)\n",
    "    word_id = np.array(word_id)\n",
    "    word_id = word_id[np.newaxis, :]\n",
    "    sequences = pad_sequences(word_id, maxlen=1700, padding='post')\n",
    "    result = np.argmax(model.predict(sequences))\n",
    "    if result == 1:\n",
    "        print(f\"Thank you~({result})\")\n",
    "    else:\n",
    "        print(f\"Fuck you!({result})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1d5706a-fd67-4ca4-8de4-2746b8b09fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Fuck you!(0)\n"
     ]
    }
   ],
   "source": [
    "I_think('真心不推荐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce555a-6d69-4103-b5f3-697898802974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
